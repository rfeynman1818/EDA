## Features:\n",
    "- **Enhanced metadata extraction** using sarpy and direct XML parsing\n",
    "- **Statistical analysis** with numpy-based computations\n",
    "- **Geographic analysis** using shapely for geometric operations\n",
    "- **Machine learning analysis** with scikit-learn (PCA, clustering)\n",
    "- **Interactive visualizations** using matplotlib and ipywidgets\n",
    "- **Progress tracking** with tqdm\n",
    "- **Export capabilities** for reports and data\n",
    "\n",
    "## Sections covered:\n",
    "1. Setup and Data Loading\n",
    "2. Basic Data Exploration\n",
    "3. Statistical Summary\n",
    "4. Overview Dashboard\n",
    "5. Distribution Analysis\n",
    "6. Geographic Analysis\n",
    "7. Temporal Pattern Analysis\n",
    "8. Correlation Analysis\n",
    "9. Machine Learning Analysis (PCA & Clustering)\n",
    "10. Interactive Widgets\n",
    "11. Export Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our custom modules\n",
    "from metadata_extractor import EnhancedSARMetadataExtractor\n",
    "from metadata_analysis import EnhancedSARMetadataAnalyzer\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Setup complete! Ready to analyze SICD metadata.\")\n",
    "print(\"Available dependencies:\")\n",
    "print(\"âœ“ numpy âœ“ matplotlib âœ“ shapely âœ“ scikit-learn âœ“ sarpy âœ“ ipywidgets âœ“ tqdm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your data path\n",
    "# Option 1: Load from a directory containing multiple XML files\n",
    "# directory_path = Path(\"/path/to/your/sicd/xml/files\")\n",
    "# metadata_extractor = EnhancedSARMetadataExtractor(directory_path)\n",
    "# metadata = metadata_extractor.parse_sicd_metadata()\n",
    "\n",
    "# Option 2: Load from a single XML file (for demonstration)\n",
    "single_file_path = Path(\"metadata_example.xml\")\n",
    "metadata_extractor = EnhancedSARMetadataExtractor()\n",
    "\n",
    "if single_file_path.exists():\n",
    "    print(f\"Loading metadata from: {single_file_path}\")\n",
    "    metadata = {single_file_path.name: metadata_extractor.extract_metadata(single_file_path)}\n",
    "    metadata_extractor.metadata = metadata\n",
    "    metadata_extractor._create_numpy_arrays()\n",
    "    print(f\"Successfully loaded metadata for {len(metadata)} file(s)\")\n",
    "else:\n",
    "    print(\"Sample file not found. Creating sample metadata for demonstration...\")\n",
    "    # Create sample metadata for demonstration\n",
    "    metadata = {\n",
    "        \"sample_file_1.xml\": {\n",
    "            'CollectorName': 'CAPELLA-X20',\n",
    "            'ModeType': 'SPOTLIGHT',\n",
    "            'NumRows': 7095,\n",
    "            'NumCols': 19584,\n",
    "            'SCP_Lat': 68.151528,\n",
    "            'SCP_Lon': 33.450816,\n",
    "            'Lat': 68.151528,\n",
    "            'Lon': 33.450816,\n",
    "            'IncidenceAng': 45.2,\n",
    "            'DateTime': '2025-01-10T14:27:07.961000Z',\n",
    "            'ImageSize_MP': 139.0,\n",
    "            'AspectRatio': 2.76\n",
    "        },\n",
    "        \"sample_file_2.xml\": {\n",
    "            'CollectorName': 'CAPELLA-X20',\n",
    "            'ModeType': 'STRIPMAP',\n",
    "            'NumRows': 5000,\n",
    "            'NumCols': 15000,\n",
    "            'SCP_Lat': 68.2,\n",
    "            'SCP_Lon': 33.5,\n",
    "            'Lat': 68.2,\n",
    "            'Lon': 33.5,\n",
    "            'IncidenceAng': 42.8,\n",
    "            'DateTime': '2025-01-11T15:30:00.000000Z',\n",
    "            'ImageSize_MP': 75.0,\n",
    "            'AspectRatio': 3.0\n",
    "        },\n",
    "        \"sample_file_3.xml\": {\n",
    "            'CollectorName': 'ICEYE-X1',\n",
    "            'ModeType': 'SPOTLIGHT',\n",
    "            'NumRows': 8000,\n",
    "            'NumCols': 12000,\n",
    "            'SCP_Lat': 68.0,\n",
    "            'SCP_Lon': 33.3,\n",
    "            'Lat': 68.0,\n",
    "            'Lon': 33.3,\n",
    "            'IncidenceAng': 47.5,\n",
    "            'DateTime': '2025-01-12T10:15:30.000000Z',\n",
    "            'ImageSize_MP': 96.0,\n",
    "            'AspectRatio': 1.5\n",
    "        }\n",
    "    }\n",
    "    metadata_extractor.metadata = metadata\n",
    "    metadata_extractor._create_numpy_arrays()\n",
    "\n",
    "# Initialize the analyzer\n",
    "analyzer = EnhancedSARMetadataAnalyzer(metadata_extractor)\n",
    "print(f\"\\nAnalyzer initialized successfully!\")\n",
    "print(f\"Loaded {len(metadata)} files with {len(metadata_extractor.column_names)} attributes each\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"=== Basic Dataset Information ===\")\n",
    "print(f\"Number of files: {len(metadata)}\")\n",
    "print(f\"Available attributes: {metadata_extractor.column_names}\")\n",
    "print(f\"Numeric data shape: {analyzer.numeric_data.shape if analyzer.numeric_data is not None else 'None'}\")\n",
    "print(f\"Numeric columns: {analyzer.numeric_columns if analyzer.numeric_columns else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample metadata entries\n",
    "print(\"=== Sample Metadata Entries ===\")\n",
    "analyzer.print_sample_metadata(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data completeness\n",
    "print(\"=== Data Completeness Analysis ===\")\n",
    "if metadata_extractor.column_names:\n",
    "    for col in metadata_extractor.column_names[:10]:  # Show first 10 columns\n",
    "        count = 0\n",
    "        for meta in metadata.values():\n",
    "            if col in meta and meta[col] is not None:\n",
    "                count += 1\n",
    "        completeness = (count / len(metadata)) * 100\n",
    "        print(f\"  {col}: {completeness:.1f}% complete ({count}/{len(metadata)} files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary statistics\n",
    "analyzer.generate_summary_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display structured statistics\n",
    "stats = metadata_extractor.get_summary_statistics()\n",
    "print(\"=== Detailed Statistics ===\")\n",
    "print(f\"\\nImage Statistics:\")\n",
    "if stats['image_statistics']:\n",
    "    for attr, attr_stats in stats['image_statistics'].items():\n",
    "        print(f\"  {attr}: mean={attr_stats['mean']:.2f}, std={attr_stats['std']:.2f}, range=[{attr_stats['min']:.2f}, {attr_stats['max']:.2f}]\")\n",
    "else:\n",
    "    print(\"  No numeric statistics available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Overview Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive overview dashboard\n",
    "print(\"Creating overview dashboard...\")\n",
    "analyzer.create_overview_dashboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image type distribution\n",
    "print(\"=== Image Type Analysis ===\")\n",
    "image_types = analyzer.count_image_types()\n",
    "print(f\"Image types found: {image_types}\")\n",
    "analyzer.plot_image_type_counts(image_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar mode distribution\n",
    "print(\"=== Radar Mode Analysis ===\")\n",
    "analyzer.plot_image_count_by_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incidence angle distribution\n",
    "print(\"=== Incidence Angle Analysis ===\")\n",
    "try:\n",
    "    # Plot for all modes\n",
    "    analyzer.plot_incidence_angle_distributions()\n",
    "    \n",
    "    # Plot for specific mode if multiple modes available\n",
    "    modes = set(meta.get('ModeType', 'Unknown') for meta in metadata.values())\n",
    "    if len(modes) > 1:\n",
    "        for mode in modes:\n",
    "            if mode != 'Unknown':\n",
    "                print(f\"\\nAnalyzing incidence angles for mode: {mode}\")\n",
    "                analyzer.plot_incidence_angle_distributions(mode_type=mode)\n",
    "                break  # Show only first mode for brevity\n",
    "except Exception as e:\n",
    "    print(f\"Could not generate incidence angle plots: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metadata distributions for key attributes\n",
    "print(\"=== Key Metadata Distributions ===\")\n",
    "key_attributes = ['NumRows', 'NumCols', 'ImageSize_MP', 'IncidenceAng', 'AspectRatio']\n",
    "\n",
    "for attr in key_attributes:\n",
    "    # Check if attribute has data\n",
    "    has_data = any(meta.get(attr) is not None for meta in metadata.values())\n",
    "    if has_data:\n",
    "        try:\n",
    "            print(f\"\\nPlotting distribution for: {attr}\")\n",
    "            analyzer.plot_metadata_distribution(\n",
    "                key=attr, \n",
    "                title=f'{attr.replace(\"_\", \" \").title()} Distribution'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot {attr}: {e}\")\n",
    "    else:\n",
    "        print(f\"No data available for {attr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic distribution analysis\n",
    "print(\"=== Geographic Analysis ===\")\n",
    "try:\n",
    "    analyzer.plot_geospatial_data()\n",
    "    \n",
    "    # Additional geographic statistics\n",
    "    lats = [meta.get('Lat') for meta in metadata.values() if meta.get('Lat') is not None]\n",
    "    lons = [meta.get('Lon') for meta in metadata.values() if meta.get('Lon') is not None]\n",
    "    \n",
    "    if lats and lons:\n",
    "        print(f\"\\nGeographic Statistics:\")\n",
    "        print(f\"  Latitude span: {max(lats) - min(lats):.4f} degrees\")\n",
    "        print(f\"  Longitude span: {max(lons) - min(lons):.4f} degrees\")\n",
    "        print(f\"  Center: ({np.mean(lats):.4f}, {np.mean(lons):.4f})\")\n",
    "        print(f\"  Approximate area: {(max(lats) - min(lats)) * (max(lons) - min(lons)) * 111**2:.0f} kmÂ²\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not generate geographic analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal pattern analysis\n",
    "print(\"=== Temporal Pattern Analysis ===\")\n",
    "try:\n",
    "    analyzer.analyze_temporal_patterns()\n",
    "except Exception as e:\n",
    "    print(f\"Could not perform temporal analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"=== Correlation Analysis ===\")\n",
    "try:\n",
    "    analyzer.create_correlation_analysis()\n",
    "except Exception as e:\n",
    "    print(f\"Could not perform correlation analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Machine Learning Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "print(\"=== Principal Component Analysis (PCA) ===\")\n",
    "try:\n",
    "    analyzer.create_pca_analysis()\n",
    "except Exception as e:\n",
    "    print(f\"Could not perform PCA analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering Analysis\n",
    "print(\"=== Clustering Analysis ===\")\n",
    "try:\n",
    "    analyzer.create_clustering_analysis()\n",
    "except Exception as e:\n",
    "    print(f\"Could not perform clustering analysis: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Interactive Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive data exploration\n",
    "print(\"=== Interactive Data Exploration ===\")\n",
    "try:\n",
    "    analyzer.create_interactive_widgets()\n",
    "except Exception as e:\n",
    "    print(f\"Could not create interactive widgets: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Advanced Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom analysis functions\n",
    "def analyze_image_characteristics():\n",
    "    \"\"\"Analyze image size characteristics.\"\"\"\n",
    "    print(\"=== Image Characteristics Analysis ===\")\n",
    "    \n",
    "    sizes = []\n",
    "    aspect_ratios = []\n",
    "    \n",
    "    for meta in metadata.values():\n",
    "        if meta.get('NumRows') and meta.get('NumCols'):\n",
    "            size = meta['NumRows'] * meta['NumCols']\n",
    "            sizes.append(size)\n",
    "            aspect_ratios.append(meta['NumCols'] / meta['NumRows'])\n",
    "    \n",
    "    if sizes:\n",
    "        print(f\"Image Size Statistics:\")\n",
    "        print(f\"  Average size: {np.mean(sizes):,.0f} pixels\")\n",
    "        print(f\"  Size range: {min(sizes):,.0f} to {max(sizes):,.0f} pixels\")\n",
    "        print(f\"  Average aspect ratio: {np.mean(aspect_ratios):.2f}\")\n",
    "        print(f\"  Aspect ratio range: {min(aspect_ratios):.2f} to {max(aspect_ratios):.2f}\")\n",
    "\n",
    "def compare_collectors():\n",
    "    \"\"\"Compare characteristics across different collectors.\"\"\"\n",
    "    print(\"\\n=== Collector Comparison ===\")\n",
    "    \n",
    "    collectors = {}\n",
    "    for meta in metadata.values():\n",
    "        collector = meta.get('CollectorName', 'Unknown')\n",
    "        if collector not in collectors:\n",
    "            collectors[collector] = []\n",
    "        collectors[collector].append(meta)\n",
    "    \n",
    "    for collector, metas in collectors.items():\n",
    "        print(f\"\\n{collector} ({len(metas)} images):\")\n",
    "        \n",
    "        # Incidence angles\n",
    "        angles = [m.get('IncidenceAng') for m in metas if m.get('IncidenceAng') is not None]\n",
    "        if angles:\n",
    "            print(f\"  Incidence angles: {np.mean(angles):.1f}Â° Â± {np.std(angles):.1f}Â°\")\n",
    "        \n",
    "        # Image sizes\n",
    "        sizes = [m.get('ImageSize_MP') for m in metas if m.get('ImageSize_MP') is not None]\n",
    "        if sizes:\n",
    "            print(f\"  Image sizes: {np.mean(sizes):.1f} Â± {np.std(sizes):.1f} MP\")\n",
    "\n",
    "def data_quality_assessment():\n",
    "    \"\"\"Assess data quality and completeness.\"\"\"\n",
    "    print(\"\\n=== Data Quality Assessment ===\")\n",
    "    \n",
    "    total_files = len(metadata)\n",
    "    total_attributes = len(metadata_extractor.column_names) if metadata_extractor.column_names else 0\n",
    "    \n",
    "    if total_attributes > 0:\n",
    "        filled_cells = 0\n",
    "        for meta in metadata.values():\n",
    "            for attr in metadata_extractor.column_names:\n",
    "                if attr in meta and meta[attr] is not None:\n",
    "                    filled_cells += 1\n",
    "        \n",
    "        completeness = (filled_cells / (total_files * total_attributes)) * 100\n",
    "        print(f\"Overall data completeness: {completeness:.1f}%\")\n",
    "        print(f\"Total data points: {filled_cells}/{total_files * total_attributes}\")\n",
    "    \n",
    "    # Check for critical missing data\n",
    "    critical_attrs = ['CollectorName', 'ModeType', 'NumRows', 'NumCols', 'SCP_Lat', 'SCP_Lon']\n",
    "    print(\"\\nCritical attribute completeness:\")\n",
    "    for attr in critical_attrs:\n",
    "        count = sum(1 for meta in metadata.values() if meta.get(attr) is not None)\n",
    "        percentage = (count / total_files) * 100\n",
    "        status = \"âœ“\" if percentage == 100 else \"âš \" if percentage >= 50 else \"âœ—\"\n",
    "        print(f\"  {status} {attr}: {percentage:.1f}% ({count}/{total_files})\")\n",
    "\n",
    "# Run custom analyses\n",
    "analyze_image_characteristics()\n",
    "compare_collectors()\n",
    "data_quality_assessment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Export Results and Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export metadata to CSV\n",
    "print(\"=== Exporting Results ===\")\n",
    "try:\n",
    "    metadata_extractor.save_metadata_csv(\"sicd_metadata_analysis.csv\")\n",
    "    print(\"âœ“ Metadata exported to CSV\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not export CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export comprehensive HTML report\n",
    "try:\n",
    "    analyzer.export_summary_report(\"enhanced_sicd_metadata_report.html\")\n",
    "    print(\"âœ“ Comprehensive HTML report exported\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not export HTML report: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of analysis results\n",
    "print(\"\\n=== Analysis Summary ===\")\n",
    "stats = metadata_extractor.get_summary_statistics()\n",
    "\n",
    "print(f\"ðŸ“Š Dataset Overview:\")\n",
    "print(f\"   â€¢ {stats['total_files']} SICD files analyzed\")\n",
    "print(f\"   â€¢ {len(stats['collectors'])} unique collectors: {list(stats['collectors'].keys())}\")\n",
    "print(f\"   â€¢ {len(stats['radar_modes'])} radar modes: {list(stats['radar_modes'].keys())}\")\n",
    "\n",
    "if stats['geographic_extent']:\n",
    "    geo = stats['geographic_extent']\n",
    "    print(f\"\\nðŸŒ Geographic Coverage:\")\n",
    "    print(f\"   â€¢ Latitude: {geo['lat_min']:.3f}Â° to {geo['lat_max']:.3f}Â°\")\n",
    "    print(f\"   â€¢ Longitude: {geo['lon_min']:.3f}Â° to {geo['lon_max']:.3f}Â°\")\n",
    "    print(f\"   â€¢ Center: ({geo['center_lat']:.3f}Â°, {geo['center_lon']:.3f}Â°)\")\n",
    "\n",
    "if stats['date_range']['start']:\n",
    "    print(f\"\\nðŸ“… Temporal Coverage:\")\n",
    "    print(f\"   â€¢ From: {stats['date_range']['start']}\")\n",
    "    print(f\"   â€¢ To: {stats['date_range']['end']}\")\n",
    "\n",
    "print(f\"\\nðŸ“ Output Files:\")\n",
    "import os\n",
    "output_files = [\n",
    "    \"sicd_metadata_analysis.csv\",\n",
    "    \"enhanced_sicd_metadata_report.html\"\n",
    "]\n",
    "\n",
    "for file in output_files:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / 1024\n",
    "        print(f\"   âœ“ {file} ({size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   âœ— {file} (not created)\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ SICD Metadata Analysis Complete!\")\n",
    "print(\"ðŸ“ˆ All visualizations generated using matplotlib\")\n",
    "print(\"ðŸ”¢ Statistical analysis performed with numpy and scikit-learn\")\n",
    "print(\"ðŸ—ºï¸ Geographic analysis using shapely\")\n",
    "print(\"âš¡ Optimized for the specified dependency constraints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Utility Functions for Further Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for custom analysis\n",
    "\n",
    "def quick_stats(attribute):\n",
    "    \"\"\"Get quick statistics for any attribute.\"\"\"\n",
    "    values = [meta.get(attribute) for meta in metadata.values() if meta.get(attribute) is not None]\n",
    "    \n",
    "    if not values:\n",
    "        print(f\"No data found for attribute: {attribute}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Statistics for {attribute}:\")\n",
    "    print(f\"  Count: {len(values)}\")\n",
    "    print(f\"  Unique values: {len(set(str(v) for v in values))}\")\n",
    "    \n",
    "    # Check if numeric\n",
    "    try:\n",
    "        numeric_values = [float(v) for v in values]\n",
    "        print(f\"  Mean: {np.mean(numeric_values):.4f}\")\n",
    "        print(f\"  Std: {np.std(numeric_values):.4f}\")\n",
    "        print(f\"  Min: {np.min(numeric_values):.4f}\")\n",
    "        print(f\"  Max: {np.max(numeric_values):.4f}\")\n",
    "        print(f\"  Median: {np.median(numeric_values):.4f}\")\n",
    "    except:\n",
    "        # Non-numeric data\n",
    "        from collections import Counter\n",
    "        value_counts = Counter(str(v) for v in values)\n",
    "        print(f\"  Most common: {value_counts.most_common(1)[0][0]} ({value_counts.most_common(1)[0][1]} occurrences)\")\n",
    "\n",
    "def filter_metadata(filter_func):\n",
    "    \"\"\"Filter metadata based on a custom function.\"\"\"\n",
    "    filtered = {k: v for k, v in metadata.items() if filter_func(v)}\n",
    "    print(f\"Filtered {len(filtered)} files out of {len(metadata)} total\")\n",
    "    return filtered\n",
    "\n",
    "def compare_modes():\n",
    "    \"\"\"Compare characteristics between different radar modes.\"\"\"\n",
    "    modes = {}\n",
    "    for meta in metadata.values():\n",
    "        mode = meta.get('ModeType', 'Unknown')\n",
    "        if mode not in modes:\n",
    "            modes[mode] = []\n",
    "        modes[mode].append(meta)\n",
    "    \n",
    "    print(\"Radar Mode Comparison:\")\n",
    "    for mode, metas in modes.items():\n",
    "        print(f\"\\n{mode} ({len(metas)} images):\")\n",
    "        \n",
    "        # Average image size\n",
    "        sizes = [m.get('ImageSize_MP') for m in metas if m.get('ImageSize_MP') is not None]\n",
    "        if sizes:\n",
    "            print(f\"  Avg image size: {np.mean(sizes):.1f} Â± {np.std(sizes):.1f} MP\")\n",
    "        \n",
    "        # Average incidence angle\n",
    "        angles = [m.get('IncidenceAng') for m in metas if m.get('IncidenceAng') is not None]\n",
    "        if angles:\n",
    "            print(f\"  Avg incidence angle: {np.mean(angles):.1f} Â± {np.std(angles):.1f}Â°\")\n",
    "        \n",
    "        # Average aspect ratio\n",
    "        ratios = [m.get('AspectRatio') for m in metas if m.get('AspectRatio') is not None]\n",
    "        if ratios:\n",
    "            print(f\"  Avg aspect ratio: {np.mean(ratios):.2f} Â± {np.std(ratios):.2f}\")\n",
    "\n",
    "def create_custom_plot(x_attr, y_attr, color_attr=None):\n",
    "    \"\"\"Create a custom scatter plot with any two attributes.\"\"\"\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "    colors = []\n",
    "    \n",
    "    for meta in metadata.values():\n",
    "        x_val = meta.get(x_attr)\n",
    "        y_val = meta.get(y_attr)\n",
    "        \n",
    "        if x_val is not None and y_val is not None:\n",
    "            try:\n",
    "                x_vals.append(float(x_val))\n",
    "                y_vals.append(float(y_val))\n",
    "                \n",
    "                if color_attr:\n",
    "                    colors.append(str(meta.get(color_attr, 'Unknown')))\n",
    "                else:\n",
    "                    colors.append('blue')\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    if x_vals and y_vals:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        if color_attr and len(set(colors)) > 1:\n",
    "            # Color by category\n",
    "            unique_colors = list(set(colors))\n",
    "            color_map = plt.cm.Set3(np.linspace(0, 1, len(unique_colors)))\n",
    "            \n",
    "            for i, cat in enumerate(unique_colors):\n",
    "                cat_x = [x_vals[j] for j in range(len(colors)) if colors[j] == cat]\n",
    "                cat_y = [y_vals[j] for j in range(len(colors)) if colors[j] == cat]\n",
    "                plt.scatter(cat_x, cat_y, color=color_map[i], label=cat, alpha=0.7)\n",
    "            plt.legend()\n",
    "        else:\n",
    "            plt.scatter(x_vals, y_vals, alpha=0.7, color='blue')\n",
    "        \n",
    "        plt.xlabel(x_attr)\n",
    "        plt.ylabel(y_attr)\n",
    "        plt.title(f'{y_attr} vs {x_attr}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No valid numeric data found for {x_attr} and {y_attr}\")\n",
    "\n",
    "# Example usage of utility functions\n",
    "print(\"=== Utility Functions Available ===\")\n",
    "print(\"Available functions:\")\n",
    "print(\"â€¢ quick_stats(attribute) - Get statistics for any attribute\")\n",
    "print(\"â€¢ filter_metadata(function) - Filter data with custom criteria\")\n",
    "print(\"â€¢ compare_modes() - Compare radar modes\")\n",
    "print(\"â€¢ create_custom_plot(x_attr, y_attr, color_attr) - Custom scatter plots\")\n",
    "\n",
    "print(\"\\nExample usage:\")\n",
    "if metadata_extractor.column_names:\n",
    "    example_attr = 'ImageSize_MP' if 'ImageSize_MP' in metadata_extractor.column_names else metadata_extractor.column_names[0]\n",
    "    print(f\"quick_stats('{example_attr}')\")\n",
    "    quick_stats(example_attr)\n",
    "    \n",
    "    print(\"\\ncompare_modes()\")\n",
    "    compare_modes()\n",
    "\n",
    "# Example filter: files with large images\n",
    "print(\"\\nExample filter - Large images (>100 MP):\")\n",
    "large_images = filter_metadata(lambda meta: meta.get('ImageSize_MP', 0) > 100)\n",
    "\n",
    "# Example custom plot\n",
    "print(\"\\nExample custom plot:\")\n",
    "if any(meta.get('NumRows') for meta in metadata.values()) and any(meta.get('NumCols') for meta in metadata.values()):\n",
    "    create_custom_plot('NumRows', 'NumCols', 'ModeType')\n",
    "else:\n",
    "    print(\"No suitable data for custom plot example\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced SICD Metadata Exploratory Data Analysis (EDA) Notebook\n",
    "\n",
    "This notebook provides a comprehensive EDA workflow for SICD metadata extracted from SAR imagery using only the specified dependencies:\n",
    "\n",
    "**Dependencies Used:**\n",
    "- numpy>=2.0.0\n",
    "- matplotlib\n",
    "- shapely\n",
    "- scikit-learn\n",
    "- scikit-image\n",
    "- sarpy\n",
    "- ipython\n",
    "- ipywidgets\n",
    "- tqdm\n",
    "\n",
    "## Features:\n",
    "-